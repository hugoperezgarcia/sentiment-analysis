# -*- coding: utf-8 -*-
"""SentimentAnalysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zYDY6RGujZnVpcd_DazwOoMIUpwfsULn
"""

import pandas as pd
import matplotlib.pyplot as plt

plt.style.use('ggplot')

df = pd.read_csv('./film_reviews_result.csv', sep='|')

"""# EDA"""

df.head()

df.describe()

"""Como con 10k nos sobra, vamos a quedarnos con las primera 1k solamente"""

df['review_text'].iloc[69]

"""Realmente solo me interesa la resena para hacer el analisis y la valoracion como target."""

df = df[['review_rate','review_text']]

df.head()

def sentimiento_txt(estrellas):
  if estrellas <= 5:
    return "negativo"
  else:
    return "positivo"

df["label_txt"] = df['review_rate'].apply(sentimiento_txt)

df.head()

df_entero = df
print(f'Entero: {df_entero.shape}')
df = df[:1000]
print(f'Cortado: {df.shape}')

"""Con 10k para este modelo nos sobra, asique nos quedaremos con 1k solamente.
Igualmente guardamos el dataframe entero para luego.
"""

bar = df['review_rate'].value_counts().sort_index().plot(kind='bar', title='N Resenas x Valoracion')
bar.set_xlabel('Valoracion')

df['label_txt'].value_counts().sort_index().plot(kind='bar', title='Cantidad de resenas de cada tipo').set_xlabel("")

"""Veo que el dataset esta desbalanceado, algo que tendre que tener en cuenta a la hora de hacer el modelo

# Modelos

Primero, voy a crear mi propio modelo de analisis de sentimiento usnado BoW y Regresion. Despues usare un modelo preentrenado con redes neuronales transformer para asi tener contexto de la frase.

# Modelo Sencillo
"""

!python -m spacy download es_core_news_sm

import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.pipeline import Pipeline
from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay
import spacy
nlp = spacy.load("es_core_news_sm")

"""Creo una nueva columna agrupando el score"""

def tokenizer_es(text):
  doc = nlp(text)
  return [token.lemma_ for token in doc if not token.is_stop and token.is_alpha]

"""Al ser TfidfVectorizer solo tokenizar para ingles, vamos a pasarle nuestro propio tokenizer."""

x_train, x_test, y_train, y_test = train_test_split(df['review_text'], df['label_txt'], test_size=0.2, random_state=42, stratify=df['label_txt'])

pipeline = Pipeline([
    ("prep", TfidfVectorizer(tokenizer=tokenizer_es, lowercase=True, max_features=5000)),
    ("pred", LogisticRegression(max_iter=1000, class_weight="balanced", random_state=42))
])

pipeline.fit(x_train, y_train)

y_pred = pipeline.predict(x_test)
print(classification_report(y_test, y_pred))

cm = confusion_matrix(y_test, y_pred, labels=pipeline.classes_)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=pipeline.classes_)
disp.plot()
plt.show()

print(pipeline.predict(["Vaya mierda, es malisima"]))
print(pipeline.predict(["Me ha gustado mucho la peli, ese actor es el mejor me encanta"]))
print(pipeline.predict(["No es nada mala, al reves, me ha impresionado para bien"]))

"""Vemos que nuestro modelo logra predecir mas o menos, aunque al no tener en cuenta el contexto de la frase en palabras que son "oximorones" o que se contradicen, como en el ultimo ejemplo: "no eres nada malo", el modelo ve las palabras "nada" o "malo", y piensa que es algo negativo

# Modelo complejo

Como entrenar un modelo transformer desde cero, requiere muchos recursos y dinero, vamos a usar un modelo preentrenado y le vamos a hacer fine-tuning para adaptarlo a nuestro caso.
"""

!pip install transformers datasets accelerate torch

from transformers import AutoTokenizer
from transformers import AutoModelForSequenceClassification
from scipy.special import softmax

MODELO = "verotei/bert-base-spanish-wwm-cased-nlp-transformers-sentiment-amazon"
tokenizer = AutoTokenizer.from_pretrained(MODELO)
model = AutoModelForSequenceClassification.from_pretrained(MODELO)

"""Elegimos un modelo que soporte el Espanol"""

def pred_bert(txt):
  encoded_text = tokenizer(txt, return_tensors='pt', padding=True, truncation=True)
  output = model(**encoded_text)
  scores = output[0][0].detach().numpy()
  scores = softmax(scores)
  scores_dict = {
      "bert_neg": scores[0],
      "bert_pos": scores[1]
  }
  return scores_dict

print(pred_bert("Vaya mierda, es malisima"))
print(pred_bert("Me ha gustado mucho la peli, ese actor es el mejor me encanta"))
print(pred_bert("No es nada mala, de hecho me ha sorprendido para bien"))

"""Vemos que aunque no hayamos hecho el fine tunning, el modelo ya es notablemente muy superior al anterior."""

from tqdm.auto import tqdm

bert_preds = []
labels = {0: 'negativo', 1: 'positivo'}

for test in tqdm(x_test, desc="Evaluacion modelo bert"):
  score = pred_bert(test)
  pred_index = np.argmax(list(score.values()))
  bert_preds.append(labels[pred_index])

print(classification_report(y_test, bert_preds))

cm_bert = confusion_matrix(y_test, bert_preds, labels=pipeline.classes_)
ConfusionMatrixDisplay(confusion_matrix=cm_bert, display_labels=pipeline.classes_).plot()

"""Los resultados del modelo bert me han sorprendido bastante para mal, me esperaba algo mejor, vamos a hacer algunas pruebas manuales, sobre todo de criticas negativas que son las que mas fala"""

print(pred_bert("No me ha gustado mucho la verdad"))
print(pred_bert("Batante floja, me esperaba mas"))
print(pred_bert("Casi me duermo viendo la peli, me ha decepcionado"))
print(pred_bert("Mas aburrida imposible"))
print(pred_bert("La mejor parte es cuando se acaba, vaya basura"))
print(pred_bert("La mejor parte es cuando se acaba"))

"""Sin embargo veo que las pruebas manuales las acierta todas, menos la ultima que era rtealmente dificil ya que es una critica totalmente ironica y dificil de detectar"""